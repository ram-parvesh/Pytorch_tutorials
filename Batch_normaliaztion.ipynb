{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cea9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Batch No"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "550b1b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib .pyplot as plt\n",
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9b3eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as dsets\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper_parameter\n",
    "num_epochs = 5\n",
    "num_classes = 10\n",
    "batch_size =100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST Datasets\n",
    "train_dataset = dsets.MNIST(root='./data',\n",
    "                                train=True,\n",
    "                                transform=transforms.ToTensor(),\n",
    "                                download=True)\n",
    "\n",
    "test_dataset = dsets.MNIST(root='./data',\n",
    "                            train=False,\n",
    "                            transform=transforms.ToTensor())\n",
    "\n",
    "#DataLoader provides queue and threads\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                            batch_size=batch_size,\n",
    "                                            shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39243fe7",
   "metadata": {},
   "source": [
    "### Simple Neural network with two fully connected layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df8b855d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self,use_batchnorm,input_size =784,hidden_dim= 256,num_classes=10):\n",
    "        super(CNN,self).__init__()\n",
    "        self.use_batchnorm = use_batchnorm\n",
    "        self.input_size = input_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        if use_batchnorm:\n",
    "            self.fc1 = nn.Linear(input_size,hidden_dim* 2,bias=False)\n",
    "            self.batch_norm1 = nn.BatchNorm1d(hidden_dim*2)\n",
    "        else:\n",
    "            self.fc1 = nn.Linear(input_size,hidden_dim* 2)\n",
    "\n",
    "        if use_batchnorm:\n",
    "            self.fc2 = nn.Linear(hidden_dim* 2,hidden_dim,bias=False)\n",
    "            self.batch_norm2 = nn.BatchNorm1d(hidden_dim)\n",
    "        else:\n",
    "            self.fc2 = nn.Linear(hidden_dim* 2,hidden_dim)\n",
    "        \n",
    "        self.fc3 = nn.Linear(hidden_dim,num_classes)  # fully connected Layer,output 10 classes\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # flatten Image\n",
    "        x = x.view(-1,28*28)  \n",
    "        # all hidden layers + optional Batch Norm + relu activation\n",
    "        x = self.fc1(x)\n",
    "        if self.use_batchnorm:\n",
    "            x = self.batch_norm1(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # Second layer\n",
    "        x = self.fc2(x)\n",
    "        if self.use_batchnorm:\n",
    "            x = self.batch_norm2(x)\n",
    "        x = F.relu(x)\n",
    "\n",
    "        # third layer no Relu or Batch Normalization\n",
    "        out = self.fc3(x)\n",
    "        return out \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd59c500",
   "metadata": {},
   "source": [
    "### training with simple neural network using batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3687d5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_step : 600\n",
      "Epoch [1/5],Step [100/600],loss:0.6437\n",
      "Epoch [1/5],Step [200/600],loss:0.5020\n",
      "Epoch [1/5],Step [300/600],loss:0.3546\n",
      "Epoch [1/5],Step [400/600],loss:0.4366\n",
      "Epoch [1/5],Step [500/600],loss:0.2312\n",
      "Epoch [1/5],Step [600/600],loss:0.1859\n",
      "Epoch [2/5],Step [100/600],loss:0.1920\n",
      "Epoch [2/5],Step [200/600],loss:0.1270\n",
      "Epoch [2/5],Step [300/600],loss:0.2105\n",
      "Epoch [2/5],Step [400/600],loss:0.1788\n",
      "Epoch [2/5],Step [500/600],loss:0.1720\n",
      "Epoch [2/5],Step [600/600],loss:0.1520\n",
      "Epoch [3/5],Step [100/600],loss:0.1556\n",
      "Epoch [3/5],Step [200/600],loss:0.1103\n",
      "Epoch [3/5],Step [300/600],loss:0.1402\n",
      "Epoch [3/5],Step [400/600],loss:0.1155\n",
      "Epoch [3/5],Step [500/600],loss:0.2240\n",
      "Epoch [3/5],Step [600/600],loss:0.1020\n",
      "Epoch [4/5],Step [100/600],loss:0.0835\n",
      "Epoch [4/5],Step [200/600],loss:0.0896\n",
      "Epoch [4/5],Step [300/600],loss:0.1314\n",
      "Epoch [4/5],Step [400/600],loss:0.1274\n",
      "Epoch [4/5],Step [500/600],loss:0.0667\n",
      "Epoch [4/5],Step [600/600],loss:0.0516\n",
      "Epoch [5/5],Step [100/600],loss:0.0702\n",
      "Epoch [5/5],Step [200/600],loss:0.0714\n",
      "Epoch [5/5],Step [300/600],loss:0.0426\n",
      "Epoch [5/5],Step [400/600],loss:0.0745\n",
      "Epoch [5/5],Step [500/600],loss:0.0808\n",
      "Epoch [5/5],Step [600/600],loss:0.0624\n",
      "Test Accuracy of the model on the 10000 test images: 97.48 %\n"
     ]
    }
   ],
   "source": [
    "learning_rate= 0.01\n",
    "model = CNN(use_batchnorm=True).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "# Train the model \n",
    "total_step = len(train_loader)\n",
    "print(\"total_step :\",total_step)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images,labels) in enumerate (train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "\n",
    "        # backward and optimize \n",
    "        optimizer.zero_grad() # clear gradient for this steps\n",
    "        loss.backward()     # calculate gradient\n",
    "        optimizer.step()    #apply gradients\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}],Step [{}/{}],loss:{:.4f}'\n",
    "            .format(epoch+1,num_epochs,i+1,total_step,loss.item()))  \n",
    "\n",
    "# test the model \n",
    "model.eval()    # eval model (batchnorm uses moving mean./varience instead of mini-batch mean and varience)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images ,labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # print(\"outputs data\",outputs.data)\n",
    "        _ ,predicted =torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'batch_norm.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d22e5330",
   "metadata": {},
   "source": [
    "#### training with simple neural network using no batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "309f69a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_step : 600\n",
      "Epoch [1/5],Step [100/600],loss:2.2642\n",
      "Epoch [1/5],Step [200/600],loss:2.1886\n",
      "Epoch [1/5],Step [300/600],loss:2.0825\n",
      "Epoch [1/5],Step [400/600],loss:1.8715\n",
      "Epoch [1/5],Step [500/600],loss:1.5559\n",
      "Epoch [1/5],Step [600/600],loss:1.2178\n",
      "Epoch [2/5],Step [100/600],loss:1.1137\n",
      "Epoch [2/5],Step [200/600],loss:0.8273\n",
      "Epoch [2/5],Step [300/600],loss:0.7541\n",
      "Epoch [2/5],Step [400/600],loss:0.5851\n",
      "Epoch [2/5],Step [500/600],loss:0.5886\n",
      "Epoch [2/5],Step [600/600],loss:0.5442\n",
      "Epoch [3/5],Step [100/600],loss:0.5028\n",
      "Epoch [3/5],Step [200/600],loss:0.3960\n",
      "Epoch [3/5],Step [300/600],loss:0.5012\n",
      "Epoch [3/5],Step [400/600],loss:0.4388\n",
      "Epoch [3/5],Step [500/600],loss:0.3448\n",
      "Epoch [3/5],Step [600/600],loss:0.3268\n",
      "Epoch [4/5],Step [100/600],loss:0.3341\n",
      "Epoch [4/5],Step [200/600],loss:0.4714\n",
      "Epoch [4/5],Step [300/600],loss:0.4561\n",
      "Epoch [4/5],Step [400/600],loss:0.3851\n",
      "Epoch [4/5],Step [500/600],loss:0.4393\n",
      "Epoch [4/5],Step [600/600],loss:0.4695\n",
      "Epoch [5/5],Step [100/600],loss:0.2513\n",
      "Epoch [5/5],Step [200/600],loss:0.5011\n",
      "Epoch [5/5],Step [300/600],loss:0.3134\n",
      "Epoch [5/5],Step [400/600],loss:0.2454\n",
      "Epoch [5/5],Step [500/600],loss:0.2649\n",
      "Epoch [5/5],Step [600/600],loss:0.2677\n",
      "Test Accuracy of the model on the 10000 test images: 90.45 %\n"
     ]
    }
   ],
   "source": [
    "learning_rate= 0.01\n",
    "model = CNN(use_batchnorm=False).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(),lr=learning_rate)\n",
    "\n",
    "# Train the model \n",
    "total_step = len(train_loader)\n",
    "print(\"total_step :\",total_step)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images,labels) in enumerate (train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "\n",
    "        # backward and optimize \n",
    "        optimizer.zero_grad() # clear gradient for this steps\n",
    "        loss.backward()     # calculate gradient\n",
    "        optimizer.step()    #apply gradients\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}],Step [{}/{}],loss:{:.4f}'\n",
    "            .format(epoch+1,num_epochs,i+1,total_step,loss.item()))  \n",
    "\n",
    "# test the model \n",
    "model.eval()    # eval model (batchnorm uses moving mean./varience instead of mini-batch mean and varience)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images ,labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # print(\"outputs data\",outputs.data)\n",
    "        _ ,predicted =torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'batch_norm.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5485244",
   "metadata": {},
   "source": [
    "### convolutional Neural Network (two convolutional neural Network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6c8742c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,num_classes):\n",
    "        super(CNN,self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(                    #input size (1,28,28)\n",
    "            nn.Conv2d(1, 16, kernel_size=5, padding=2), #in_channel=1,out_channel=16,filter size=5\n",
    "            nn.BatchNorm2d(16),     # o/p size (16,28,28)\n",
    "            nn.ReLU(),              #activation  o/p size  (16,28,28)\n",
    "            nn.MaxPool2d(2))        #output size after pooling (16,14,14)\n",
    "        \n",
    "        \n",
    "        self.layer2 = nn.Sequential(    #input shape (16,14,14)\n",
    "            nn.Conv2d(16, 32, kernel_size=5, padding=2),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2))          #output shape (32,7,7)\n",
    "        \n",
    "        self.fc = nn.Linear(32*7*7, num_classes)     # fully connected Layer,output 10 classes\n",
    "    \n",
    "    def forward(self,x):\n",
    "        \n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        \n",
    "        out = out.view(out.size(0),-1)    #flatten the output of conv2d to feed into fully connected layers\n",
    "        \n",
    "        out = self.fc(out)\n",
    "        return out \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62681715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_step : 600\n",
      "Epoch [1/5],Step [100/600],loss:0.1866\n",
      "Epoch [1/5],Step [200/600],loss:0.1029\n",
      "Epoch [1/5],Step [300/600],loss:0.0826\n",
      "Epoch [1/5],Step [400/600],loss:0.0431\n",
      "Epoch [1/5],Step [500/600],loss:0.0457\n",
      "Epoch [1/5],Step [600/600],loss:0.0220\n",
      "Epoch [2/5],Step [100/600],loss:0.0922\n",
      "Epoch [2/5],Step [200/600],loss:0.0232\n",
      "Epoch [2/5],Step [300/600],loss:0.0847\n",
      "Epoch [2/5],Step [400/600],loss:0.1794\n",
      "Epoch [2/5],Step [500/600],loss:0.0404\n",
      "Epoch [2/5],Step [600/600],loss:0.0451\n",
      "Epoch [3/5],Step [100/600],loss:0.0172\n",
      "Epoch [3/5],Step [200/600],loss:0.0032\n",
      "Epoch [3/5],Step [300/600],loss:0.0739\n",
      "Epoch [3/5],Step [400/600],loss:0.0137\n",
      "Epoch [3/5],Step [500/600],loss:0.0665\n",
      "Epoch [3/5],Step [600/600],loss:0.0385\n",
      "Epoch [4/5],Step [100/600],loss:0.0649\n",
      "Epoch [4/5],Step [200/600],loss:0.0104\n",
      "Epoch [4/5],Step [300/600],loss:0.1143\n",
      "Epoch [4/5],Step [400/600],loss:0.0508\n",
      "Epoch [4/5],Step [500/600],loss:0.0565\n",
      "Epoch [4/5],Step [600/600],loss:0.0127\n",
      "Epoch [5/5],Step [100/600],loss:0.0050\n",
      "Epoch [5/5],Step [200/600],loss:0.0011\n",
      "Epoch [5/5],Step [300/600],loss:0.0064\n",
      "Epoch [5/5],Step [400/600],loss:0.0075\n",
      "Epoch [5/5],Step [500/600],loss:0.0826\n",
      "Epoch [5/5],Step [600/600],loss:0.0883\n",
      "Test Accuracy of the model on the 10000 test images: 99.13 %\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model = CNN(num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n",
    "\n",
    "# Train the model \n",
    "total_step = len(train_loader)\n",
    "print(\"total_step :\",total_step)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i,(images,labels) in enumerate (train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # forward pass \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs,labels)\n",
    "\n",
    "        # backward and optimize \n",
    "        optimizer.zero_grad() # clear gradient for this steps\n",
    "        loss.backward()     # calculate gradient\n",
    "        optimizer.step()    #apply gradients\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}],Step [{}/{}],loss:{:.4f}'\n",
    "            .format(epoch+1,num_epochs,i+1,total_step,loss.item()))  \n",
    "\n",
    "# test the model \n",
    "model.eval()    # eval model (batchnorm uses moving mean./varience instead of mini-batch mean and varience)\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for images ,labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # print(\"outputs data\",outputs.data)\n",
    "        _ ,predicted =torch.max(outputs.data,1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "    print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'cnn.ckpt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3cdebf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
