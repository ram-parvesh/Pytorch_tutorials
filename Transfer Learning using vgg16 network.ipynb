{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc60108e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets ,models,transforms\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bec5788e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check cude is available or not\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c919a778",
   "metadata": {},
   "source": [
    "### Load and Transform our Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f188afe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'flower_photos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52e8856e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define training and test data directories\n",
    "train_dir = os.path.join(data_dir,'train/')\n",
    "test_dir = os.path.join(data_dir , 'test/')\n",
    "\n",
    "classes = ['daisy','dandelion','roses','sunflowers','tulips']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d7c40a",
   "metadata": {},
   "source": [
    "### Transforming the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd488576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training images:  3130\n",
      "Num test images:  540\n"
     ]
    }
   ],
   "source": [
    "data_transform = transforms.Compose([transforms.RandomResizedCrop(224),\n",
    "                                     transforms.ToTensor()])\n",
    "train_data = datasets.ImageFolder(train_dir, transform=data_transform)\n",
    "test_data = datasets.ImageFolder(test_dir, transform=data_transform)\n",
    "\n",
    "# print out some data stats\n",
    "print('Num training images: ', len(train_data))\n",
    "print('Num test images: ', len(test_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a0bb68",
   "metadata": {},
   "source": [
    "### DataLoaders and Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6df8c8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define dataloader parameters\n",
    "batch_size = 20\n",
    "num_workers=0\n",
    "\n",
    "# prepare data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, \n",
    "                                           num_workers=num_workers, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size, \n",
    "                                          num_workers=num_workers, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242f2d7f",
   "metadata": {},
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a362ae0c",
   "metadata": {},
   "source": [
    "To define a model for training we'll follow these steps:\n",
    "\n",
    "1. Load in a pre-trained VGG16 model\n",
    "2. \"Freeze\" all the parameters, so the net acts as a fixed feature extractor\n",
    "3. Remove the last layer\n",
    "4. Replace the last layer with a linear classifier of our own\n",
    "###  Freezing simply means that the parameters in the pre-trained model will not change during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "61dbd938",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (3): ReLU(inplace=True)\n",
      "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (5): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): ReLU(inplace=True)\n",
      "    (7): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (10): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (13): ReLU(inplace=True)\n",
      "    (14): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (15): ReLU(inplace=True)\n",
      "    (16): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (17): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (18): ReLU(inplace=True)\n",
      "    (19): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (25): ReLU(inplace=True)\n",
      "    (26): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (27): ReLU(inplace=True)\n",
      "    (28): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))\n",
      "  (classifier): Sequential(\n",
      "    (0): Linear(in_features=25088, out_features=4096, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Dropout(p=0.5, inplace=False)\n",
      "    (3): Linear(in_features=4096, out_features=4096, bias=True)\n",
      "    (4): ReLU(inplace=True)\n",
      "    (5): Dropout(p=0.5, inplace=False)\n",
      "    (6): Linear(in_features=4096, out_features=1000, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#load the pretrained model from pytorch\n",
    "vgg16 = models.vgg16(pretrained=True)\n",
    "\n",
    "# Print out the model structure\n",
    "print(vgg16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8cd7fbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4096\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "print(vgg16.classifier[6].in_features)\n",
    "print(vgg16.classifier[6].out_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc75275b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#freeze training for all \"features\" layers\n",
    "for param in vgg16.features.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bf107d",
   "metadata": {},
   "source": [
    "### Final Classifier Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d28fba96",
   "metadata": {},
   "source": [
    "Once you have the pre-trained feature extractor, you just need to modify and/or add to the final, fully-connected classifier layers. In this case, we suggest that you repace the last layer in the vgg classifier group of layers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d372ff1",
   "metadata": {},
   "source": [
    "This layer should see as input the number of features produced by the portion of the network that you are not changing, and produce an appropriate number of outputs for the flower classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7592146d",
   "metadata": {},
   "source": [
    "### You can access any layer in a pretrained network by name and (sometimes) number, i.e. vgg16.classifier[6] is the sixth layer in a group of layers named \"classifier\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6a9407c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "n_inputs = vgg16.classifier[6].in_features\n",
    "\n",
    "# add last linear layer (n_inputs -> 5 flower classes)\n",
    "# new layers automatically have requires_grad = True\n",
    "\n",
    "last_layer = nn.Linear(n_inputs, len(classes))\n",
    "\n",
    "vgg16.classifier[6] = last_layer\n",
    "\n",
    "# model to device\n",
    "vgg16.to(device)\n",
    "\n",
    "\n",
    "# check to see that your last layer produces the expected number of outputs\n",
    "print(vgg16.classifier[6].out_features)\n",
    "#print(vgg16)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9765d0fc",
   "metadata": {},
   "source": [
    "### Specifying Loss function and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1052b9",
   "metadata": {},
   "source": [
    "## only train the classifier parameters ,features parameters are frozen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8769a4e",
   "metadata": {},
   "source": [
    "#### in optimizer for back propagation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a1a6abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# specify loss function (categorical cross-entropy)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# specify optimizer (stochastic gradient descent) and learning rate = 0.001\n",
    "optimizer = optim.SGD(vgg16.classifier.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e5ac39",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a38278c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Batch 20 loss: 1.5212907016277313\n",
      "Epoch 1, Batch 40 loss: 1.3896093189716339\n",
      "Epoch 1, Batch 60 loss: 1.1862610220909118\n",
      "Epoch 1, Batch 80 loss: 1.1190831691026688\n",
      "Epoch 1, Batch 100 loss: 1.0770229220390319\n",
      "Epoch 1, Batch 120 loss: 0.9912109941244125\n",
      "Epoch 1, Batch 140 loss: 0.9197895050048828\n",
      "Epoch 2, Batch 20 loss: 0.8587419986724854\n",
      "Epoch 2, Batch 40 loss: 0.8469494223594666\n",
      "Epoch 2, Batch 60 loss: 0.8397821396589279\n",
      "Epoch 2, Batch 80 loss: 0.8569969236850739\n",
      "Epoch 2, Batch 100 loss: 0.7360910311341285\n",
      "Epoch 2, Batch 120 loss: 0.7508710920810699\n",
      "Epoch 2, Batch 140 loss: 0.7467984184622765\n"
     ]
    }
   ],
   "source": [
    "# number of epochs to train the model\n",
    "n_epochs = 2\n",
    "\n",
    "for epoch in range(1, n_epochs+1):\n",
    "\n",
    "    # keep track of training and validation loss\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    ###################\n",
    "    # train the model #\n",
    "    ###################\n",
    "    # model by default is set to train\n",
    "    for idx, (data, target) in enumerate(train_loader):\n",
    "        # move tensors to GPU if CUDA is available\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # clear the gradients of all optimized variables\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass: compute predicted outputs by passing inputs to the model\n",
    "        output = vgg16(data)\n",
    "        \n",
    "        # calculate the batch loss\n",
    "        loss = criterion(output, target)\n",
    "        # backward pass: compute gradient of the loss with respect to model parameters\n",
    "        loss.backward()\n",
    "        # perform a single optimization step (parameter update)\n",
    "        optimizer.step()\n",
    "        # update training loss \n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        if idx % 20 == 19:    # print training loss every specified number of mini-batches\n",
    "            print('Epoch %d, Batch %d loss: %.16f' %\n",
    "                  (epoch, idx + 1, train_loss / 20))\n",
    "            train_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "056bcd53",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2f4b91",
   "metadata": {},
   "source": [
    "Below you see the test accuracy for each flower class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "94a9ae6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 78.33333333333333 %\n"
     ]
    }
   ],
   "source": [
    "# track test loss \n",
    "# over 5 flower classes\n",
    "test_loss = 0.0\n",
    "correct = 0 #list(0. for i in range(5))\n",
    "total =0 # list(0. for i in range(5))\n",
    "\n",
    "vgg16.eval() # eval mode\n",
    "\n",
    "# iterate over test data\n",
    "for data, target in test_loader:\n",
    "    # move tensors to GPU if CUDA is available\n",
    "    data, target = data.to(device), target.to(device)\n",
    "    # forward pass: compute predicted outputs by passing inputs to the model\n",
    "    output = vgg16(data)\n",
    "    # calculate the batch loss\n",
    "    loss = criterion(output, target)\n",
    "    # update  test loss \n",
    "    test_loss += loss.item()*data.size(0)\n",
    "    \n",
    "    # convert output probabilities to predicted class\n",
    "    _, pred = torch.max(output.data, 1)    \n",
    "    total += target.size(0)\n",
    "    correct += (pred==target).sum().item()\n",
    "print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38305702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
